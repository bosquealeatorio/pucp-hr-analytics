{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HR Analytics\n",
    "\n",
    "<img src = 'https://datahack-prod.s3.ap-south-1.amazonaws.com/__sized__/contest_cover/hr_1920x480_s5WuoZs-thumbnail-1200x1200-90.jpg'>\n",
    "\n",
    "Practice Problem: https://datahack.analyticsvidhya.com/contest/wns-analytics-hackathon-2018-1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HR Analytics\n",
    "\n",
    "HR analytics is revolutionising the way human resources departments operate, leading to higher efficiency and better results overall. Human resources has been using analytics for years. However, the collection, processing and analysis of data has been largely manual, and given the nature of human resources dynamics and HR KPIs, the approach has been constraining HR. Therefore, it is surprising that HR departments woke up to the utility of machine learning so late in the game. Here is an opportunity to try predictive analytics in identifying the employees most likely to get promoted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Your client is a large MNC and they have 9 broad verticals across the organisation. One of the problem your client is facing is around identifying the right people for promotion *(only for manager position and below)* and prepare them in time. Currently the process, they are following is:\n",
    "\n",
    "* They first identify a set of employees based on recommendations/ past performance\n",
    "* Selected employees go through the separate training and evaluation program for each vertical. These programs are based on the required skill of each vertical\n",
    "* At the end of the program, based on various factors such as training performance, KPI completion (only employees with KPIs completed greater than 60% are considered) etc., employee gets promotion\n",
    "\n",
    "For above mentioned process, the final promotions are only announced after the evaluation and this leads to delay in transition to their new roles. Hence, company needs your help in identifying the eligible candidates at a particular checkpoint so that they can expedite the entire promotion cycle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/09/wns_hack_im_1.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They have provided multiple attributes around Employee's past and current performance along with demographics. Now, The task is to predict whether a potential promotee at checkpoint in the test set will be promoted or not after the evaluation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metric\n",
    "\n",
    "The evaluation metric for this competition is F1 Score.\n",
    "\n",
    "## Public and Private Split\n",
    "\n",
    "Test data is further randomly divided into Public (40%) and Private (60%) data.\n",
    "\n",
    "Your initial responses will be checked and scored on the Public data.\n",
    "The final rankings would be based on your private score which will be published once the competition is over."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                  *  C:\\Users\\antho\\Anaconda3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda info --envs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from pathlib import Path\n",
    "import random\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "seed = 2020\n",
    "random.seed(seed)\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 400)\n",
    "sns.set()\n",
    "\n",
    "DATA = Path('../../data') \n",
    "RAW  = DATA/'raw'\n",
    "PROCESSED = DATA/'processed'\n",
    "SUBMISSIONS = DATA/'submissions'    \n",
    "\n",
    "MODEL = Path('../../model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_columns = 'employee_id'\n",
    "target = 'is_promoted'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'preprocess_v1_capping_values.pkl',\n",
       " 'preprocess_v1_impute_values.pkl',\n",
       " 'preprocess_v1_ohe.pkl',\n",
       " 'preprocess_v1_ohe_columns.pkl',\n",
       " 'preprocess_v1_over50_train.csv',\n",
       " 'preprocess_v1_scaler.pkl',\n",
       " 'preprocess_v1_smote20_train.csv',\n",
       " 'preprocess_v1_smote50_train.csv',\n",
       " 'preprocess_v1_smoteTomek20_train.csv',\n",
       " 'preprocess_v1_smoteTomek50_train.csv',\n",
       " 'preprocess_v1_train.csv',\n",
       " 'preprocess_v1_under50_train.csv',\n",
       " 'preprocess_v1_val.csv',\n",
       " 'preprocess_v2_capping_values.pkl',\n",
       " 'preprocess_v2_knnimputation.pkl',\n",
       " 'preprocess_v2_ohe.pkl',\n",
       " 'preprocess_v2_ohe_columns.pkl',\n",
       " 'preprocess_v2_over50_train.csv',\n",
       " 'preprocess_v2_scaler.pkl',\n",
       " 'preprocess_v2_scalerimputation.pkl',\n",
       " 'preprocess_v2_smote20_train.csv',\n",
       " 'preprocess_v2_smote50_train.csv',\n",
       " 'preprocess_v2_smoteTomek20_train.csv',\n",
       " 'preprocess_v2_smoteTomek50_train.csv',\n",
       " 'preprocess_v2_test.csv',\n",
       " 'preprocess_v2_train.csv',\n",
       " 'preprocess_v2_under50_train.csv',\n",
       " 'preprocess_v2_val.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(f'{PROCESSED}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento V1 sin balanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocess_v1_over50_train.csv',\n",
       " 'preprocess_v1_smote20_train.csv',\n",
       " 'preprocess_v1_smote50_train.csv',\n",
       " 'preprocess_v1_smoteTomek20_train.csv',\n",
       " 'preprocess_v1_smoteTomek50_train.csv',\n",
       " 'preprocess_v1_train.csv',\n",
       " 'preprocess_v1_under50_train.csv',\n",
       " 'preprocess_v2_over50_train.csv',\n",
       " 'preprocess_v2_smote20_train.csv',\n",
       " 'preprocess_v2_smote50_train.csv',\n",
       " 'preprocess_v2_smoteTomek20_train.csv',\n",
       " 'preprocess_v2_smoteTomek50_train.csv',\n",
       " 'preprocess_v2_train.csv',\n",
       " 'preprocess_v2_under50_train.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_train = [file for file in os.listdir(f'{PROCESSED}') if file.endswith('train.csv')]\n",
    "preproc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocess_v1_val.csv', 'preprocess_v2_val.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_val = [file for file in os.listdir(f'{PROCESSED}') if file.endswith('val.csv')]\n",
    "preproc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: preprocess_v1_over50_train.csv      \tnrows: 80224 \t%target train: 0.5000 \t%target val: 0.0852\n",
      "label: preprocess_v1_smote20_train.csv     \tnrows: 48134 \t%target train: 0.1667 \t%target val: 0.0852\n",
      "label: preprocess_v1_smote50_train.csv     \tnrows: 80224 \t%target train: 0.5000 \t%target val: 0.0852\n",
      "label: preprocess_v1_smoteTomek20_train.csv \tnrows: 46412 \t%target train: 0.1543 \t%target val: 0.0852\n",
      "label: preprocess_v1_smoteTomek50_train.csv \tnrows: 79638 \t%target train: 0.5000 \t%target val: 0.0852\n",
      "label: preprocess_v1_train.csv             \tnrows: 43846 \t%target train: 0.0852 \t%target val: 0.0852\n",
      "label: preprocess_v1_under50_train.csv     \tnrows: 7468 \t%target train: 0.5000 \t%target val: 0.0852\n",
      "label: preprocess_v2_over50_train.csv      \tnrows: 80224 \t%target train: 0.5000 \t%target val: 0.0852\n",
      "label: preprocess_v2_smote20_train.csv     \tnrows: 48134 \t%target train: 0.1667 \t%target val: 0.0852\n",
      "label: preprocess_v2_smote50_train.csv     \tnrows: 80224 \t%target train: 0.5000 \t%target val: 0.0852\n",
      "label: preprocess_v2_smoteTomek20_train.csv \tnrows: 46390 \t%target train: 0.1541 \t%target val: 0.0852\n",
      "label: preprocess_v2_smoteTomek50_train.csv \tnrows: 79638 \t%target train: 0.5000 \t%target val: 0.0852\n",
      "label: preprocess_v2_train.csv             \tnrows: 43846 \t%target train: 0.0852 \t%target val: 0.0852\n",
      "label: preprocess_v2_under50_train.csv     \tnrows: 7468 \t%target train: 0.5000 \t%target val: 0.0852\n"
     ]
    }
   ],
   "source": [
    "for train_file in sorted(preproc_train):\n",
    "    df_train = pd.read_csv(f'{PROCESSED}/{train_file}', compression = 'zip')\n",
    "    df_val = pd.read_csv(f'{PROCESSED}/{preproc_val[0]}', compression = 'zip')\n",
    "    \n",
    "    print(f'label: {train_file:35} \\tnrows: {len(df_train)} \\t%target train: {df_train[target].mean():.4f} \\t%target val: {df_val[target].mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'preprocess_v1_train.csv'\n",
    "val_file = 'preprocess_v1_val.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "n_neighbors = list(range(5,10))\n",
    "p=[1,2]\n",
    "#random_state= [seed]\n",
    "cv_grid = dict(n_neighbors=n_neighbors, p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "params_grid = list(ParameterGrid(cv_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 1}\n",
      "preprocess_v1_over50_train.csv\n",
      "----------------------------------------------------------------------\n",
      "auc_train: 0.948033 \tauc_val: 0.646267 \tf1_train: 0.950598 \tf1_val: 0.292578\n",
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 1}\n",
      "preprocess_v1_smote20_train.csv\n",
      "----------------------------------------------------------------------\n",
      "auc_train: 0.849801 \tauc_val: 0.586403 \tf1_train: 0.770056 \tf1_val: 0.250441\n",
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 1}\n",
      "preprocess_v1_smote50_train.csv\n",
      "----------------------------------------------------------------------\n",
      "auc_train: 0.951050 \tauc_val: 0.643785 \tf1_train: 0.953186 \tf1_val: 0.295737\n",
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 1}\n",
      "preprocess_v1_smoteTomek20_train.csv\n",
      "----------------------------------------------------------------------\n",
      "auc_train: 0.853254 \tauc_val: 0.589248 \tf1_train: 0.783278 \tf1_val: 0.261741\n",
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 1}\n",
      "preprocess_v1_smoteTomek50_train.csv\n",
      "----------------------------------------------------------------------\n",
      "auc_train: 0.953464 \tauc_val: 0.643389 \tf1_train: 0.955319 \tf1_val: 0.297090\n",
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 1}\n",
      "preprocess_v1_train.csv\n",
      "----------------------------------------------------------------------\n",
      "auc_train: 0.583763 \tauc_val: 0.538339 \tf1_train: 0.281168 \tf1_val: 0.144928\n",
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 1}\n",
      "preprocess_v1_under50_train.csv\n",
      "----------------------------------------------------------------------\n",
      "auc_train: 0.801419 \tauc_val: 0.668461 \tf1_train: 0.800645 \tf1_val: 0.259880\n",
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 1}\n",
      "preprocess_v2_over50_train.csv\n",
      "----------------------------------------------------------------------\n",
      "auc_train: 0.952869 \tauc_val: 0.654187 \tf1_train: 0.954956 \tf1_val: 0.293253\n",
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 1}\n",
      "preprocess_v2_smote20_train.csv\n",
      "----------------------------------------------------------------------\n",
      "auc_train: 0.849527 \tauc_val: 0.585618 \tf1_train: 0.769804 \tf1_val: 0.248680\n",
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 1}\n",
      "preprocess_v2_smote50_train.csv\n",
      "----------------------------------------------------------------------\n",
      "auc_train: 0.950975 \tauc_val: 0.644593 \tf1_train: 0.953131 \tf1_val: 0.295880\n",
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 1}\n",
      "preprocess_v2_smoteTomek20_train.csv\n",
      "----------------------------------------------------------------------\n",
      "auc_train: 0.853788 \tauc_val: 0.588912 \tf1_train: 0.784270 \tf1_val: 0.261307\n",
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 1}\n",
      "preprocess_v2_smoteTomek50_train.csv\n",
      "----------------------------------------------------------------------\n",
      "auc_train: 0.953163 \tauc_val: 0.642541 \tf1_train: 0.955041 \tf1_val: 0.295169\n",
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 1}\n",
      "preprocess_v2_train.csv\n",
      "----------------------------------------------------------------------\n",
      "auc_train: 0.584128 \tauc_val: 0.538289 \tf1_train: 0.282107 \tf1_val: 0.144796\n",
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 1}\n",
      "preprocess_v2_under50_train.csv\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [1:05:12<9:46:49, 3912.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_train: 0.802625 \tauc_val: 0.671237 \tf1_train: 0.801882 \tf1_val: 0.261859\n",
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 2}\n",
      "preprocess_v1_over50_train.csv\n",
      "----------------------------------------------------------------------\n",
      "auc_train: 0.946325 \tauc_val: 0.651668 \tf1_train: 0.949060 \tf1_val: 0.296661\n",
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 2}\n",
      "preprocess_v1_smote20_train.csv\n",
      "----------------------------------------------------------------------\n",
      "auc_train: 0.853142 \tauc_val: 0.611356 \tf1_train: 0.759620 \tf1_val: 0.287375\n",
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 2}\n",
      "preprocess_v1_smote50_train.csv\n",
      "----------------------------------------------------------------------\n",
      "auc_train: 0.939644 \tauc_val: 0.664970 \tf1_train: 0.942960 \tf1_val: 0.305788\n",
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 2}\n",
      "preprocess_v1_smoteTomek20_train.csv\n",
      "----------------------------------------------------------------------\n",
      "auc_train: 0.864267 \tauc_val: 0.614511 \tf1_train: 0.779359 \tf1_val: 0.298130\n",
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 2}\n",
      "preprocess_v1_smoteTomek50_train.csv\n",
      "----------------------------------------------------------------------\n",
      "auc_train: 0.940556 \tauc_val: 0.670795 \tf1_train: 0.943710 \tf1_val: 0.311318\n",
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 2}\n",
      "preprocess_v1_train.csv\n",
      "----------------------------------------------------------------------\n",
      "auc_train: 0.598016 \tauc_val: 0.554396 \tf1_train: 0.318450 \tf1_val: 0.193057\n",
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 2}\n",
      "preprocess_v1_under50_train.csv\n",
      "----------------------------------------------------------------------\n",
      "auc_train: 0.789100 \tauc_val: 0.656665 \tf1_train: 0.788959 \tf1_val: 0.249789\n",
      "----------------------------------------------------------------------\n",
      "{'n_neighbors': 5, 'p': 2}\n",
      "preprocess_v2_over50_train.csv\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame(columns = ['preproc_label', 'model_label', 'método', 'parámetros', 'columnas_out',\n",
    "                                     'auc_train', 'auc_val', 'threshold','f1_train', 'f1_val'])\n",
    "\n",
    "\n",
    "for xgb_params in tqdm(params_grid):\n",
    "    \n",
    "    for train_file in sorted(preproc_train):\n",
    "\n",
    "        preproc_label = train_file.split('_train')[0]\n",
    "\n",
    "        print('----------------------------------------------------------------------')\n",
    "        print(xgb_params)\n",
    "        print(train_file)\n",
    "        print('----------------------------------------------------------------------')\n",
    "\n",
    "        df_train = pd.read_csv(f'{PROCESSED}/{train_file}', compression = 'zip')\n",
    "        df_val = pd.read_csv(f'{PROCESSED}/{preproc_val[0]}', compression = 'zip')\n",
    "\n",
    "        X_train, y_train = df_train.drop(target, axis = 1), df_train[target]\n",
    "        X_val, y_val = df_val.drop(target, axis = 1), df_val[target]\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors = xgb_params[\"n_neighbors\"],p =xgb_params[\"p\"])\n",
    "        knn_fit = knn.fit( X_train,y_train )\n",
    "                        \n",
    "        \n",
    "        #xgb_params_export = xgb_params.copy()\n",
    "        #xgb_params_export.update(logi_fit.attributes())\n",
    "\n",
    "        probs_train = knn.predict(X_train)\n",
    "        probs_val = knn.predict(X_val)\n",
    "\n",
    "        auc_train = roc_auc_score(y_train, probs_train)\n",
    "        auc_val = roc_auc_score(y_val, probs_val)\n",
    "\n",
    "        #best threshold\n",
    "        prec, recall, threshold = precision_recall_curve(y_train, probs_train)\n",
    "        prec_recall = pd.DataFrame({'prec': prec[:-1], 'recall': recall[:-1], 'threshold': threshold})\n",
    "        prec_recall['f1'] = 2*prec_recall['prec']*prec_recall['recall'] / (prec_recall['prec'] + prec_recall['recall'])\n",
    "        prec_recall = prec_recall.sort_values(by = 'f1', ascending = False).head(1)\n",
    "\n",
    "        #f1 scores\n",
    "        best_threshold = prec_recall['threshold'].values[0]\n",
    "        f1_train = prec_recall['f1'].values[0]\n",
    "\n",
    "        labels_val = np.where(probs_val >= best_threshold, 1, 0)\n",
    "        f1_val = f1_score(y_val, labels_val)\n",
    "\n",
    "        print(f'auc_train: {auc_train:.6f} \\tauc_val: {auc_val:.6f} \\tf1_train: {f1_train:.6f} \\tf1_val: {f1_val:.6f}')\n",
    "\n",
    "        results = [preproc_label, 'KNeighborsClassifier', 'fit', xgb_params, '',\n",
    "                  auc_train, auc_val, best_threshold, f1_train, f1_val]\n",
    "\n",
    "\n",
    "        df_results.loc[len(df_results)] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = DATA/'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(f'{MODELS}/KNeighborsClassifier.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('KNeighborsClassifier.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_excel(f'{MODELS}/KNeighborsClassifier.xlsx', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
