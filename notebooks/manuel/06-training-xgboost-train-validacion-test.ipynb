{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HR Analytics\n",
    "\n",
    "<img src = 'https://datahack-prod.s3.ap-south-1.amazonaws.com/__sized__/contest_cover/hr_1920x480_s5WuoZs-thumbnail-1200x1200-90.jpg'>\n",
    "\n",
    "Practice Problem: https://datahack.analyticsvidhya.com/contest/wns-analytics-hackathon-2018-1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HR Analytics\n",
    "\n",
    "HR analytics is revolutionising the way human resources departments operate, leading to higher efficiency and better results overall. Human resources has been using analytics for years. However, the collection, processing and analysis of data has been largely manual, and given the nature of human resources dynamics and HR KPIs, the approach has been constraining HR. Therefore, it is surprising that HR departments woke up to the utility of machine learning so late in the game. Here is an opportunity to try predictive analytics in identifying the employees most likely to get promoted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Your client is a large MNC and they have 9 broad verticals across the organisation. One of the problem your client is facing is around identifying the right people for promotion *(only for manager position and below)* and prepare them in time. Currently the process, they are following is:\n",
    "\n",
    "* They first identify a set of employees based on recommendations/ past performance\n",
    "* Selected employees go through the separate training and evaluation program for each vertical. These programs are based on the required skill of each vertical\n",
    "* At the end of the program, based on various factors such as training performance, KPI completion (only employees with KPIs completed greater than 60% are considered) etc., employee gets promotion\n",
    "\n",
    "For above mentioned process, the final promotions are only announced after the evaluation and this leads to delay in transition to their new roles. Hence, company needs your help in identifying the eligible candidates at a particular checkpoint so that they can expedite the entire promotion cycle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/09/wns_hack_im_1.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They have provided multiple attributes around Employee's past and current performance along with demographics. Now, The task is to predict whether a potential promotee at checkpoint in the test set will be promoted or not after the evaluation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metric\n",
    "\n",
    "The evaluation metric for this competition is F1 Score.\n",
    "\n",
    "## Public and Private Split\n",
    "\n",
    "Test data is further randomly divided into Public (40%) and Private (60%) data.\n",
    "\n",
    "Your initial responses will be checked and scored on the Public data.\n",
    "The final rankings would be based on your private score which will be published once the competition is over."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.12 |Anaconda, Inc.| (default, Sep  8 2020, 17:50:39) \\n[GCC Clang 10.0.0 ]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\r\n",
      "#\r\n",
      "micromaster              /Users/manuel/.conda/envs/micromaster\r\n",
      "                         /Users/manuel/.julia/conda/3\r\n",
      "base                  *  /Users/manuel/opt/anaconda3\r\n",
      "belcorp                  /Users/manuel/opt/anaconda3/envs/belcorp\r\n",
      "courseragcp              /Users/manuel/opt/anaconda3/envs/courseragcp\r\n",
      "iapucp                   /Users/manuel/opt/anaconda3/envs/iapucp\r\n",
      "mitxpro                  /Users/manuel/opt/anaconda3/envs/mitxpro\r\n",
      "style-transfer           /Users/manuel/opt/anaconda3/envs/style-transfer\r\n",
      "taller-dmc               /Users/manuel/opt/anaconda3/envs/taller-dmc\r\n",
      "udacity                  /Users/manuel/opt/anaconda3/envs/udacity\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!conda info --envs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from pathlib import Path\n",
    "import random\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "seed = 2020\n",
    "random.seed(seed)\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 400)\n",
    "sns.set()\n",
    "\n",
    "DATA = Path('../../data') \n",
    "RAW  = DATA/'raw'\n",
    "PROCESSED = DATA/'processed'\n",
    "SUBMISSIONS = DATA/'submissions'    \n",
    "MODEL_RESULTS = DATA/'models'\n",
    "\n",
    "MODEL = Path('../../model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_columns = 'employee_id'\n",
    "target = 'is_promoted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_label = 'xgboost_20'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elección del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgboost_baseline.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(f'{MODEL_RESULTS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preproc_label</th>\n",
       "      <th>model_label</th>\n",
       "      <th>método</th>\n",
       "      <th>parámetros</th>\n",
       "      <th>columnas_out</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_val</th>\n",
       "      <th>threshold</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>preprocess_v1_over50</td>\n",
       "      <td>xgboost_baseline</td>\n",
       "      <td>fit</td>\n",
       "      <td>{'eval_metric': 'auc', 'gamma': 0, 'max_depth'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.925740</td>\n",
       "      <td>0.912398</td>\n",
       "      <td>0.519916</td>\n",
       "      <td>0.857260</td>\n",
       "      <td>0.387935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>preprocess_v1_smote20</td>\n",
       "      <td>xgboost_baseline</td>\n",
       "      <td>fit</td>\n",
       "      <td>{'eval_metric': 'auc', 'gamma': 0, 'max_depth'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.963750</td>\n",
       "      <td>0.902189</td>\n",
       "      <td>0.363386</td>\n",
       "      <td>0.809268</td>\n",
       "      <td>0.303494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>preprocess_v1_smote50</td>\n",
       "      <td>xgboost_baseline</td>\n",
       "      <td>fit</td>\n",
       "      <td>{'eval_metric': 'auc', 'gamma': 0, 'max_depth'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.994993</td>\n",
       "      <td>0.903298</td>\n",
       "      <td>0.397081</td>\n",
       "      <td>0.970218</td>\n",
       "      <td>0.316904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>preprocess_v1_smoteTomek20</td>\n",
       "      <td>xgboost_baseline</td>\n",
       "      <td>fit</td>\n",
       "      <td>{'eval_metric': 'auc', 'gamma': 0, 'max_depth'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.984355</td>\n",
       "      <td>0.896496</td>\n",
       "      <td>0.335935</td>\n",
       "      <td>0.873732</td>\n",
       "      <td>0.352239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>preprocess_v1_smoteTomek50</td>\n",
       "      <td>xgboost_baseline</td>\n",
       "      <td>fit</td>\n",
       "      <td>{'eval_metric': 'auc', 'gamma': 0, 'max_depth'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993239</td>\n",
       "      <td>0.902251</td>\n",
       "      <td>0.425842</td>\n",
       "      <td>0.967290</td>\n",
       "      <td>0.307300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>preprocess_v2_smote50</td>\n",
       "      <td>xgboost_baseline</td>\n",
       "      <td>fit</td>\n",
       "      <td>{'eval_metric': 'auc', 'gamma': 5, 'max_depth'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993078</td>\n",
       "      <td>0.909270</td>\n",
       "      <td>0.449836</td>\n",
       "      <td>0.966119</td>\n",
       "      <td>0.519499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>preprocess_v2_smoteTomek20</td>\n",
       "      <td>xgboost_baseline</td>\n",
       "      <td>fit</td>\n",
       "      <td>{'eval_metric': 'auc', 'gamma': 5, 'max_depth'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.972369</td>\n",
       "      <td>0.909576</td>\n",
       "      <td>0.357857</td>\n",
       "      <td>0.834015</td>\n",
       "      <td>0.543329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>preprocess_v2_smoteTomek50</td>\n",
       "      <td>xgboost_baseline</td>\n",
       "      <td>fit</td>\n",
       "      <td>{'eval_metric': 'auc', 'gamma': 5, 'max_depth'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993535</td>\n",
       "      <td>0.909469</td>\n",
       "      <td>0.429405</td>\n",
       "      <td>0.966711</td>\n",
       "      <td>0.522215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>preprocess_v2</td>\n",
       "      <td>xgboost_baseline</td>\n",
       "      <td>fit</td>\n",
       "      <td>{'eval_metric': 'auc', 'gamma': 5, 'max_depth'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.917067</td>\n",
       "      <td>0.909057</td>\n",
       "      <td>0.256593</td>\n",
       "      <td>0.542299</td>\n",
       "      <td>0.531928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>preprocess_v2_under50</td>\n",
       "      <td>xgboost_baseline</td>\n",
       "      <td>fit</td>\n",
       "      <td>{'eval_metric': 'auc', 'gamma': 5, 'max_depth'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.899683</td>\n",
       "      <td>0.893918</td>\n",
       "      <td>0.386634</td>\n",
       "      <td>0.835035</td>\n",
       "      <td>0.337800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>504 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  preproc_label       model_label método  \\\n",
       "0          preprocess_v1_over50  xgboost_baseline    fit   \n",
       "1         preprocess_v1_smote20  xgboost_baseline    fit   \n",
       "2         preprocess_v1_smote50  xgboost_baseline    fit   \n",
       "3    preprocess_v1_smoteTomek20  xgboost_baseline    fit   \n",
       "4    preprocess_v1_smoteTomek50  xgboost_baseline    fit   \n",
       "..                          ...               ...    ...   \n",
       "499       preprocess_v2_smote50  xgboost_baseline    fit   \n",
       "500  preprocess_v2_smoteTomek20  xgboost_baseline    fit   \n",
       "501  preprocess_v2_smoteTomek50  xgboost_baseline    fit   \n",
       "502               preprocess_v2  xgboost_baseline    fit   \n",
       "503       preprocess_v2_under50  xgboost_baseline    fit   \n",
       "\n",
       "                                            parámetros  columnas_out  \\\n",
       "0    {'eval_metric': 'auc', 'gamma': 0, 'max_depth'...           NaN   \n",
       "1    {'eval_metric': 'auc', 'gamma': 0, 'max_depth'...           NaN   \n",
       "2    {'eval_metric': 'auc', 'gamma': 0, 'max_depth'...           NaN   \n",
       "3    {'eval_metric': 'auc', 'gamma': 0, 'max_depth'...           NaN   \n",
       "4    {'eval_metric': 'auc', 'gamma': 0, 'max_depth'...           NaN   \n",
       "..                                                 ...           ...   \n",
       "499  {'eval_metric': 'auc', 'gamma': 5, 'max_depth'...           NaN   \n",
       "500  {'eval_metric': 'auc', 'gamma': 5, 'max_depth'...           NaN   \n",
       "501  {'eval_metric': 'auc', 'gamma': 5, 'max_depth'...           NaN   \n",
       "502  {'eval_metric': 'auc', 'gamma': 5, 'max_depth'...           NaN   \n",
       "503  {'eval_metric': 'auc', 'gamma': 5, 'max_depth'...           NaN   \n",
       "\n",
       "     auc_train   auc_val  threshold  f1_train    f1_val  \n",
       "0     0.925740  0.912398   0.519916  0.857260  0.387935  \n",
       "1     0.963750  0.902189   0.363386  0.809268  0.303494  \n",
       "2     0.994993  0.903298   0.397081  0.970218  0.316904  \n",
       "3     0.984355  0.896496   0.335935  0.873732  0.352239  \n",
       "4     0.993239  0.902251   0.425842  0.967290  0.307300  \n",
       "..         ...       ...        ...       ...       ...  \n",
       "499   0.993078  0.909270   0.449836  0.966119  0.519499  \n",
       "500   0.972369  0.909576   0.357857  0.834015  0.543329  \n",
       "501   0.993535  0.909469   0.429405  0.966711  0.522215  \n",
       "502   0.917067  0.909057   0.256593  0.542299  0.531928  \n",
       "503   0.899683  0.893918   0.386634  0.835035  0.337800  \n",
       "\n",
       "[504 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.read_csv(f'{MODEL_RESULTS}/xgboost_baseline.csv')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preproc_label</th>\n",
       "      <th>model_label</th>\n",
       "      <th>método</th>\n",
       "      <th>parámetros</th>\n",
       "      <th>columnas_out</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_val</th>\n",
       "      <th>threshold</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>preprocess_v1</td>\n",
       "      <td>xgboost_baseline</td>\n",
       "      <td>fit</td>\n",
       "      <td>{'eval_metric': 'auc', 'gamma': 0, 'max_depth'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.936164</td>\n",
       "      <td>0.912828</td>\n",
       "      <td>0.264434</td>\n",
       "      <td>0.578571</td>\n",
       "      <td>0.555488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>preprocess_v2_smoteTomek20</td>\n",
       "      <td>xgboost_baseline</td>\n",
       "      <td>fit</td>\n",
       "      <td>{'eval_metric': 'auc', 'gamma': 2.5, 'max_dept...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.977697</td>\n",
       "      <td>0.914479</td>\n",
       "      <td>0.355524</td>\n",
       "      <td>0.853583</td>\n",
       "      <td>0.548159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>preprocess_v2_smoteTomek50</td>\n",
       "      <td>xgboost_baseline</td>\n",
       "      <td>fit</td>\n",
       "      <td>{'eval_metric': 'auc', 'gamma': 0, 'max_depth'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.995018</td>\n",
       "      <td>0.912623</td>\n",
       "      <td>0.398115</td>\n",
       "      <td>0.970562</td>\n",
       "      <td>0.548117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>preprocess_v2_smote50</td>\n",
       "      <td>xgboost_baseline</td>\n",
       "      <td>fit</td>\n",
       "      <td>{'eval_metric': 'auc', 'gamma': 0, 'max_depth'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.994278</td>\n",
       "      <td>0.912402</td>\n",
       "      <td>0.402771</td>\n",
       "      <td>0.968889</td>\n",
       "      <td>0.546985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>preprocess_v2_over50</td>\n",
       "      <td>xgboost_baseline</td>\n",
       "      <td>fit</td>\n",
       "      <td>{'eval_metric': 'auc', 'gamma': 2.5, 'max_dept...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993614</td>\n",
       "      <td>0.912404</td>\n",
       "      <td>0.367706</td>\n",
       "      <td>0.968155</td>\n",
       "      <td>0.545322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  preproc_label       model_label método  \\\n",
       "19                preprocess_v1  xgboost_baseline    fit   \n",
       "290  preprocess_v2_smoteTomek20  xgboost_baseline    fit   \n",
       "67   preprocess_v2_smoteTomek50  xgboost_baseline    fit   \n",
       "9         preprocess_v2_smote50  xgboost_baseline    fit   \n",
       "245        preprocess_v2_over50  xgboost_baseline    fit   \n",
       "\n",
       "                                            parámetros  columnas_out  \\\n",
       "19   {'eval_metric': 'auc', 'gamma': 0, 'max_depth'...           NaN   \n",
       "290  {'eval_metric': 'auc', 'gamma': 2.5, 'max_dept...           NaN   \n",
       "67   {'eval_metric': 'auc', 'gamma': 0, 'max_depth'...           NaN   \n",
       "9    {'eval_metric': 'auc', 'gamma': 0, 'max_depth'...           NaN   \n",
       "245  {'eval_metric': 'auc', 'gamma': 2.5, 'max_dept...           NaN   \n",
       "\n",
       "     auc_train   auc_val  threshold  f1_train    f1_val  \n",
       "19    0.936164  0.912828   0.264434  0.578571  0.555488  \n",
       "290   0.977697  0.914479   0.355524  0.853583  0.548159  \n",
       "67    0.995018  0.912623   0.398115  0.970562  0.548117  \n",
       "9     0.994278  0.912402   0.402771  0.968889  0.546985  \n",
       "245   0.993614  0.912404   0.367706  0.968155  0.545322  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = df_results.sort_values(by = 'f1_val', ascending = False).head()\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_label = df_results.head(1)['preproc_label'].values[0]\n",
    "params = df_results.head(1)['parámetros'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'preprocess_v1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'eval_metric': 'auc', 'gamma': 0, 'max_depth': 3, 'min_child_weight': 10, 'objective': 'reg:logistic', 'seed': 2020}\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f'{PROCESSED}/{preproc_label}_train.csv', compression = 'zip')\n",
    "df_val = pd.read_csv(f'{PROCESSED}/{preproc_label}_val.csv', compression = 'zip')\n",
    "df_test = pd.read_csv(f'{PROCESSED}/{preproc_label}_test.csv', compression = 'zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43846, 61), (10962, 61), (23490, 61))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train.drop(target, axis = 1), df_train[target]\n",
    "X_val, y_val = df_val.drop(target, axis = 1), df_val[target]\n",
    "\n",
    "ids_test = df_test[id_columns]\n",
    "X_test = df_test.drop(id_columns, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.74958\tval-auc:0.75430\n",
      "Multiple eval metrics have been passed: 'val-auc' will be used for early stopping.\n",
      "\n",
      "Will train until val-auc hasn't improved in 20 rounds.\n",
      "[50]\ttrain-auc:0.91216\tval-auc:0.90858\n",
      "[100]\ttrain-auc:0.92173\tval-auc:0.91223\n",
      "Stopping. Best iteration:\n",
      "[93]\ttrain-auc:0.92097\tval-auc:0.91229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtrain =  xgb.DMatrix(data=X_train, label = y_train)\n",
    "dval  = xgb.DMatrix(data=X_val,   label = y_val)\n",
    "\n",
    "watch_list  = [(dtrain,'train'),(dval,'val')]\n",
    "\n",
    "xgb_fit = xgb.train(params = eval(params), dtrain = dtrain, \n",
    "                    num_boost_round = 1000, early_stopping_rounds = 20, \n",
    "                    evals = watch_list, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_train: 0.920889 \tauc_val: 0.912261 \tf1_train: 0.536326 \tf1_val: 0.528829\n"
     ]
    }
   ],
   "source": [
    "probs_train = xgb_fit.predict(dtrain, ntree_limit = xgb_fit.best_iteration)\n",
    "probs_val = xgb_fit.predict(dval, ntree_limit = xgb_fit.best_iteration)\n",
    "\n",
    "auc_train = roc_auc_score(y_train, probs_train)\n",
    "auc_val = roc_auc_score(y_val, probs_val)\n",
    "\n",
    "#best threshold\n",
    "prec, recall, threshold = precision_recall_curve(y_train, probs_train)\n",
    "prec_recall = pd.DataFrame({'prec': prec[:-1], 'recall': recall[:-1], 'threshold': threshold})\n",
    "prec_recall['f1'] = 2*prec_recall['prec']*prec_recall['recall'] / (prec_recall['prec'] + prec_recall['recall'])\n",
    "prec_recall = prec_recall.sort_values(by = 'f1', ascending = False).head(1)\n",
    "\n",
    "#f1 scores\n",
    "best_threshold = prec_recall['threshold'].values[0]\n",
    "f1_train = prec_recall['f1'].values[0]\n",
    "\n",
    "labels_val = np.where(probs_val >= best_threshold, 1, 0)\n",
    "f1_val = f1_score(y_val, labels_val)\n",
    "\n",
    "print(f'auc_train: {auc_train:.6f} \\tauc_val: {auc_val:.6f} \\tf1_train: {f1_train:.6f} \\tf1_val: {f1_val:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with complete train + validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54808, 61)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat([df_train, df_val])\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train.drop(target, axis = 1), df_train[target]\n",
    "dtrain =  xgb.DMatrix(data=X_train, label = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_fit = xgb.train(params = eval(params), dtrain = dtrain, \n",
    "                    num_boost_round = xgb_fit.best_iteration, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_train: 0.919474 \tf1_train: 0.534151\n"
     ]
    }
   ],
   "source": [
    "probs_train = xgb_fit.predict(dtrain)\n",
    "\n",
    "auc_train = roc_auc_score(y_train, probs_train)\n",
    "\n",
    "#best threshold\n",
    "prec, recall, threshold = precision_recall_curve(y_train, probs_train)\n",
    "prec_recall = pd.DataFrame({'prec': prec[:-1], 'recall': recall[:-1], 'threshold': threshold})\n",
    "prec_recall['f1'] = 2*prec_recall['prec']*prec_recall['recall'] / (prec_recall['prec'] + prec_recall['recall'])\n",
    "prec_recall = prec_recall.sort_values(by = 'f1', ascending = False).head(1)\n",
    "\n",
    "#f1 scores\n",
    "best_threshold = prec_recall['threshold'].values[0]\n",
    "f1_train = prec_recall['f1'].values[0]\n",
    "\n",
    "print(f'auc_train: {auc_train:.6f} \\tf1_train: {f1_train:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest =  xgb.DMatrix(data = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_test = xgb_fit.predict(dtest)\n",
    "labels_test = np.where(probs_test >= best_threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>is_promoted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74430</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64486</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23485</th>\n",
       "      <td>53478</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23486</th>\n",
       "      <td>25600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23487</th>\n",
       "      <td>45409</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23488</th>\n",
       "      <td>1186</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23489</th>\n",
       "      <td>5973</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23490 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       employee_id  is_promoted\n",
       "0             8724            0\n",
       "1            74430            0\n",
       "2            72255            0\n",
       "3            38562            0\n",
       "4            64486            0\n",
       "...            ...          ...\n",
       "23485        53478            0\n",
       "23486        25600            0\n",
       "23487        45409            0\n",
       "23488         1186            0\n",
       "23489         5973            1\n",
       "\n",
       "[23490 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[id_columns] = ids_test\n",
    "df_test[target] = labels_test\n",
    "df_test.get([id_columns, target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.get([id_columns, target]).to_csv(f'{SUBMISSIONS}/{model_label}_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iapucp",
   "language": "python",
   "name": "iapucp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
